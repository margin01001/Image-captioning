{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCe6YpTA70tZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FmerCZWEizN"
      },
      "outputs": [],
      "source": [
        "# Download the dataset from github (Original dataset)\n",
        "# !pip install wget\n",
        "# import wget\n",
        "# import zipfile\n",
        "\n",
        "# wget.download('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip')\n",
        "# wget.download('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip')\n",
        "\n",
        "\n",
        "# zip_flicker_dataset = '/content/drive/MyDrive/Data/Flickr8k_Dataset.zip'\n",
        "# zip_flicker_text = '/content/drive/MyDrive/Data/Flickr8k_text.zip'\n",
        "\n",
        "# with zipfile.ZipFile(zip_flicker_dataset) as zip:\n",
        "#   zip.extractall('/content/drive/MyDrive/Data/Image-Captioning-Data/Flicker-Data')\n",
        "# with zipfile.ZipFile(zip_flicker_text) as zip:\n",
        "#   zip.extractall('/content/drive/MyDrive/Data/Image-Captioning-Data/Flicker-Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD_84Ne0SOu0"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "IMAGE_DATA_DIR = '/content/drive/MyDrive/Data/Image-Captioning-Data/Flicker-Data/Flicker8k_Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVCwQOhNrgLI",
        "outputId": "3c8b0b27-600c-449c-f719-a4d8233d27a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "553476096/553467096 [==============================] - 4s 0us/step\n",
            "input_1\n",
            "1 block1_conv1 (3, 3, 3, 64)\n",
            "2 block1_conv2 (3, 3, 64, 64)\n",
            "block1_pool\n",
            "4 block2_conv1 (3, 3, 64, 128)\n",
            "5 block2_conv2 (3, 3, 128, 128)\n",
            "block2_pool\n",
            "7 block3_conv1 (3, 3, 128, 256)\n",
            "8 block3_conv2 (3, 3, 256, 256)\n",
            "9 block3_conv3 (3, 3, 256, 256)\n",
            "block3_pool\n",
            "11 block4_conv1 (3, 3, 256, 512)\n",
            "12 block4_conv2 (3, 3, 512, 512)\n",
            "13 block4_conv3 (3, 3, 512, 512)\n",
            "block4_pool\n",
            "15 block5_conv1 (3, 3, 512, 512)\n",
            "16 block5_conv2 (3, 3, 512, 512)\n",
            "17 block5_conv3 (3, 3, 512, 512)\n",
            "block5_pool\n",
            "flatten\n",
            "fc1\n",
            "fc2\n",
            "predictions\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(include_top=True)\n",
        "\n",
        "for i in range(len(base_model.layers)):\n",
        "    curr_layer = base_model.layers[i]\n",
        "    if 'conv' not in curr_layer.name:\n",
        "        print(curr_layer.name)\n",
        "        # to get config print -> curr_layer.get_config()\n",
        "        continue\n",
        "    \n",
        "    filters, biasis = curr_layer.get_weights()\n",
        "    \n",
        "    print(i, curr_layer.name, filters.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting every layers output in vgg16\n",
        "features_list = [layer.output for layer in base_model.layers]\n",
        "feat_extraction_model = tf.keras.Model(inputs=base_model.input, outputs=features_list)"
      ],
      "metadata": {
        "id": "srZs-J_-FfeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PEPjfg33F-OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B2sBe8x-bng",
        "outputId": "c9f3b468-b0c6-4caf-f458-131dd771c8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='fc2/Relu:0', description=\"created by layer 'fc2'\")\n"
          ]
        }
      ],
      "source": [
        "print(base_model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8frsq8GaVIBP",
        "outputId": "13aa50c1-c8c8-4560-bd6a-a44a3ebfaf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 0\n",
            "Non-trainable params: 138,357,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(include_top=True)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Taking till Flaten layer\n",
        "model = Model(inputs = base_model.inputs, outputs = base_model.layers[-2].output)\n",
        "\n",
        "img = image.img_to_array(image.load_img('/content/drive/MyDrive/Data/Image-Captioning-Data/Flicker-Data/Flicker8k_Dataset/35506150_cbdb630f4f.jpg', target_size=(224, 224)))\n",
        "img = img.reshape(-1, 224, 224, 3)\n",
        "img = preprocess_input(img)\n",
        "\n",
        "# model.summary()\n",
        "img_features = model.predict(img)\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T0tV9QwdmqI",
        "outputId": "bfa3f02a-9104-4f7d-dcfa-e396424cb934"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4096)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# (no. of samples, features)\n",
        "img_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx3Bi57d7cY0"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1n1VFM97lD8"
      },
      "outputs": [],
      "source": [
        "# features = {}\n",
        "\n",
        "# for full_img_name in tqdm(os.listdir(IMAGE_DATA_DIR)):\n",
        "#     # removing image format from image name\n",
        "#     img_name = full_img_name.split('.')[0]\n",
        "\n",
        "#     img_dir = os.path.join(IMAGE_DATA_DIR, full_img_name)\n",
        "\n",
        "#     # loading image and converting to numpy array and reshaping it to (224, 224, 3)\n",
        "#     # Image size is 224 because thats the image size in which vgg16 is trained on\n",
        "#     loaded_img = image.img_to_array(image.load_img(img_dir, target_size=(224, 224))).reshape(-1, 224, 224, 3)\n",
        "    \n",
        "#     #preprocessing data according to vgg16\n",
        "#     loaded_img = preprocess_input(loaded_img)\n",
        "\n",
        "#     features[img_name] = model.predict(loaded_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving features and model"
      ],
      "metadata": {
        "id": "KMVOzxXPcsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving features\n",
        "# pickle.dump(features, open('/content/drive/MyDrive/Data/Image-Captioning-Data/features.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "zFTPo9pwMv05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(model, open('/content/drive/MyDrive/Data/Image-Captioning-Data/model.h5', 'wb'))"
      ],
      "metadata": {
        "id": "jBnZcRlwMvnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WI9PXC4B5fC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mx_caption_length = 0\n",
        "def load_caption_data(filepath):\n",
        "    caption_mapping = {}\n",
        "    global mx_caption_length\n",
        "\n",
        "    # Reading caption file\n",
        "    with open(filepath, 'r') as file:\n",
        "        captions = file.read()\n",
        "\n",
        "    #looping through every line\n",
        "    for line in captions.split('\\n'):\n",
        "        #spliting b/w captions and image name\n",
        "        split_line = line.split()\n",
        "        if len(split_line) <= 3:\n",
        "            print(split_line)\n",
        "            continue\n",
        "        # fetching image name without format\n",
        "        img_name = split_line[0].split('.')[0]\n",
        "        # fetching caption\n",
        "        curr_caption = ' '.join(split_line[1:])\n",
        "        mx_caption_length = max(mx_caption_length, len(split_line))\n",
        "\n",
        "        # if img_name key is not in dict then declared that key\n",
        "        if img_name not in caption_mapping:\n",
        "            caption_mapping[img_name] = []\n",
        "        # appending every caption for an img_name\n",
        "        caption_mapping[img_name].append(curr_caption)\n",
        "    \n",
        "    return caption_mapping"
      ],
      "metadata": {
        "id": "LZaMl01sMvkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_caption_data('/content/drive/MyDrive/Data/Image-Captioning-Data/Flicker-Text/Flickr8k.token.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGf3qASkMvh2",
        "outputId": "5d5c4947-a977-46ba-bf9e-e2e524819c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2165461920_1a4144eb2b.jpg#0', 'dogs', 'racing']\n",
            "['2428275562_4bde2bc5ea.jpg#0', 'A']\n",
            "['244760301_5809214866.jpg#3', 'People', 'walking']\n",
            "['256085101_2c2617c5d0.jpg#3', 'Dog', 'yawns']\n",
            "['2714703706_d21c5cb8df.jpg#0', 'dogs', 'playing']\n",
            "['2755314937_1e974bf2b5.jpg#3', 'broken', 'image']\n",
            "['2862481071_86c65d46fa.jpg#4', 'Trucks', 'racing']\n",
            "['2929669711_b2d5a640f0.jpg#4', 'man', 'surfing']\n",
            "['3108732084_565b423162.jpg#2', 'a', 'snowboarder']\n",
            "['3125309108_1011486589.jpg#2', 'rugby', 'match']\n",
            "['3154693053_cfcd05c226.jpg#0', 'A', 'basketball']\n",
            "['3189251454_03b76c2e92.jpg#3', 'dog', 'barking']\n",
            "['3237760601_5334f3f3b5.jpg#1', 'A', 'skier']\n",
            "['3360823754_90967276ec.jpg#3', 'Man', 'skateboarding']\n",
            "['3640443200_b8066f37f6.jpg#0', 'a']\n",
            "['3664928753_7b0437fedf.jpg#3', 'Javelin', 'competition']\n",
            "['3694071771_ce760db4c7.jpg#0', 'a', 'cyclist']\n",
            "[]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyNByEu6MvfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_out = base_model.output\n",
        "base_model_out = tf.keras.layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)"
      ],
      "metadata": {
        "id": "NAZmm9G8Mvci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(base_model.input, base_model_out)"
      ],
      "metadata": {
        "id": "udAwSrv7NaW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROc05TcxNhWW",
        "outputId": "af7a70f6-b0ba-4a5f-8006-b26a970aec4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1000)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 0\n",
            "Non-trainable params: 138,357,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3reDfjmN9bO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Feature-Extraction-For-Image-Captioning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}